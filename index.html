<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>István Sárándi - 3D human analysis</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="István Sárándi's personal site.">
    <meta name="keywords" content="3D human pose, computer vision, deep learning, AI, machine learning, phd student, grad student, Sarandi, Istvan, RWTH, Hungarian, Hungary, Germany, Aachen">

    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="css/style.css">
    <script defer src="js/fontawesome.all.min.js"></script>
</head>
<body>

<img class="profile-pic" src="images/istvan_pic.jpg">
<div class="short-bio">
    <h1 class="name">István Sárándi</h1>
    <a href="mailto:istvan.sarandi@uni-tuebingen.de">istvan.sarandi@uni-tuebingen.de</a>
    <div class="statement">
        I'm a postdoctoral researcher in the
        <a href="https://virtualhumans.mpi-inf.mpg.de">Real Virtual Humans</a> group headed by
        <a href="https://scholar.google.de/citations?user=OpXMNnMAAAAJ">Prof. Gerard Pons-Moll</a>
        at the <a href="https://uni-tuebingen.de">University of Tübingen</a> in Germany.

    </div>
</div>
<div class="links-top">
    <a href="cv_istvan_sarandi.pdf">
        <span class="icon"><i class="fas fa-file-pdf"></i></span>
        CV
    </a><a href="https://scholar.google.com/citations?user=ZeCLyhAAAAAJ">
        <span class="icon"><i class="ai ai-google-scholar"></i></span>
        Google Scholar
    </a><a href="https://github.com/isarandi">
        <span class="icon"><i class="fab fa-github"></i></span>
        GitHub
    </a><a href="https://linkedin.com/in/istvansarandi">
        <span class="icon"><i class="fab fa-linkedin"></i></span>
        LinkedIn
    </a><a href="https://twitter.com/Istvan_Sarandi">
        <span class="icon"><i class="fab fa-twitter"></i></span>
        Twitter
    </a><a href="https://orcid.org/0000-0002-5686-3214">
        <span class="icon"><i class="ai ai-orcid"></i></span>
        ORCID
    </a>
</div>

<p class="bio">
    My research focus is robust and efficient <strong>3D human understanding</strong>.
    Among others, I am excited about research on holistic capture of humans in context, as well as uncertainty-aware
    semi- and self-supervised learning for human-related tasks.
</p>

<p class="bio">
    I did my PhD in <a
        href="https://scholar.google.com/citations?user=ZcULDB0AAAAJ">Prof. Bastian Leibe</a>’s
    <a href="https://vision.rwth-aachen.de">Computer Vision Group</a>
    at <a href="https://rwth-aachen.de">RWTH Aachen University</a> in Germany.
    That work was funded in part through a scholarship of the <a href="https://www.bosch-research-foundation.com">Bosch Research Foundation</a>.
    My methods have won 3D human pose estimation competitions at ECCV 2018 and 2020, and I have received Outstanding
    Reviewer Awards at CVPR 2021 and 2022.
</p>

<p class="bio">
    Before that, I completed my master’s in Computer Science also at RWTH Aachen, where I initially worked on medical image processing
    with <a href="https://scholar.google.de/citations?user=sdsxvdwAAAAJ">Prof. Thomas M. Deserno</a>,
    then joined <a href="https://scholar.google.com/citations?user=ZcULDB0AAAAJ">Prof. Bastian Leibe</a>’s Computer
    Vision Group as a student research assistant and wrote my master’s thesis on visual crowd counting and pedestrian flow analysis.
    Prior to that, I received my bachelor’s degree in Computer Engineering from the Budapest University of Technology and Economics in my native
    Hungary, with a thesis on machine learning approaches for natural language processing in medical diagnosis classification.
</p>

<h2 id="news">News</h2>
<ul>
    <li>[2023-12] Defended <a href="#phd-thesis">my PhD thesis</a>!</li>
    <li>[2023-03] Joined the <a href="https://virtualhumans.mpi-inf.mpg.de">Real Virtual Humans</a> research group at the University of Tübingen!</li>
    <li>[2023-01] Gave an invited talk at <a href="https://research.adobe.com">Adobe Research</a> in San Jose, California, USA.</li>
    <li>[2023-01] Presented <a href="dozens">a paper</a> at <a href="https://wacv2023.thecvf.com">WACV 2023</a> in Waikoloa, Hawaii, USA.</li>
    <li>[2022-11] Showcased our work at the <a href="https://www.neuroaix.de/en/">neuroAIx Frontiers Workshop</a> in Aachen, Germany.</li>
    <li>[2022-10] Presented <a href="eccv22_demo">a live demo</a> at <a href="https://eccv2022.ecva.net">ECCV 2022</a> in Tel Aviv, Israel.</li>
    <li>[2022-07] Gave a talk at the <a href="https://virtualhumans.mpi-inf.mpg.de/">Real Virtual Humans</a> research group at the University of Tübingen, Germany.</li>
    <li>[2022-06] Attended  <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> in New Orleans, USA, where I received an Outstanding Reviewer Award.</li>
</ul>

<h2 id="publications">Publications</h2>

<div class="paper" id="sarandi23wacv">
    <a href="dozens"><img src="paper_thumbnails/sarandi23wacv.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="dozens">
            Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge
            Between Skeleton Formats
        </a></div>
        <div class="paper-authors"><u>István Sárándi</u>, Alexander Hermans, Bastian Leibe</div>
        <div class="paper-venue">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023. (Waikoloa, HI,
            USA)
        </div>
        <div class="paper-links">
            <a href="dozens">
                <span class="icon"><i class="fa fa-rocket"></i></span>
                Project
            </a><a href="https://arxiv.org/abs/2212.14474">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="#">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code (soon)
            </a><a href="https://youtube.com/watch?v=6IW6oImq3RM ">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                Talk
            </a><a href="https://vision.rwth-aachen.de/media/papers/223/sarandi-wacv2023-dozens-poster.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Poster
            </a><a href="https://doi.org/10.1109/WACV56688.2023.00297">
                <span class="icon"><i class="fa fa-external-link-alt"></i></span>
                doi
            </a><a href="javascript:toggleBibtex('bibtex_wacv23')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_wacv23">@inproceedings{Sarandi2023dozens,
    title = {Learning {3D} Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats},
    author = {S\'ar\'andi, Istv\'an and Hermans, Alexander and Leibe, Bastian},
    booktitle = {IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    year = {2023}
}</pre>
    </div>
</div>

<div class="paper" id="sarandi22eccvd">
    <a href="eccv22_demo"><img src="paper_thumbnails/eccv22_demo.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="eccv22_demo">
            Demo: Accurate and Efficient Absolute 3D Human Pose Estimation Trained on Dozens of Datasets
        </a></div>
        <div class="paper-authors"><u>István Sárándi</u></div>
        <div class="paper-venue">European Conference on Computer Vision <a href="https://eccv2022.ecva.net/program/demo-list/">Demo Track</a> (not a paper), 2022. (Tel Aviv, Israel)
        </div>
        <div class="paper-links">
            <a href="eccv22_demo">
                <span class="icon"><i class="fa fa-rocket"></i></span>
                Webpage
            </a><a href="media/sarandi-eccv2022-demo-poster.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Poster
            </a><a href="https://youtu.be/sAF0atPmEec">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                Teaser Video
            </a><a href="media/eccv22_demo_short_live.mp4">
                <span class="icon"><i class="fa fa-film"></i></span>
                Live Video
            </a><a href="media/eccv22_demo_photo.jpg">
                <span class="icon"><i class="fa fa-image"></i></span>
                Photo
            </a>
        </div>
    </div>
</div>

<div class="paper" id="sarandi21tbiom">
    <a href="https://arxiv.org/abs/2007.07227"><img src="paper_thumbnails/metrabs.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/2007.07227">
            MeTRAbs: Metric-Scale Truncation-Robust Heatmaps for Absolute 3D Human Pose Estimation
        </a></div>
        <div class="paper-authors"><u>István Sárándi</u>, Timm Linder, Kai O. Arras, Bastian Leibe</div>
        <div class="paper-venue">IEEE Transactions on Biometrics, Behavior, and Identity Science (T-BIOM), 2021;<strong>3</strong>(1):16–30<br>(Special Journal Issue: Selected Best
            Works From Automated Face and Gesture Recognition)
        </div>
        <span class="icon"><i class="fas fa-trophy"></i></span>
        <a href="https://virtualhumans.mpi-inf.mpg.de/3DPW_Challenge">1st place in the ECCV 2020
            3D Poses in the Wild Challenge!</a>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/2007.07227">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="https://github.com/isarandi/metrabs">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code
            </a><a href="https://youtube.com/watch?v=BemM8-Lx47g">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                Talk
            </a><a href="media/sarandi_metrabs_slides.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Slides (FG)
            </a><a href="media/metrabs_3dpw_slides.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Slides (ECCVW)
            </a><a href="https://youtube.com/watch?v=4VFKiiW9RCQ">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                New Qualitative Video
            </a><a href="https://doi.org/10.1109/TBIOM.2020.3037257">
                <span class="icon"><i class="fa fa-external-link-alt"></i></span>
                doi
            </a><a href="javascript:toggleBibtex('bibtex_tbiom21')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_tbiom21">@article{Sarandi2021metrabs,
    title = {{MeTRAbs:} Metric-Scale Truncation-Robust Heatmaps for Absolute {3D} Human Pose Estimation},
    author = {S\'ar\'andi, Istv\'an and Linder, Timm and Arras, Kai O. and Leibe, Bastian},
    journal = {IEEE Transactions on Biometrics, Behavior, and Identity Science (T-BIOM)},
    year = {2021},
    volume = {3},
    number = {1},
    pages = {16--30}
}</pre>
    </div>
</div>

<div class="paper" id="knoche20cvprw">
    <a href="https://arxiv.org/abs/2006.04898"><img src="paper_thumbnails/knoche20cvprw.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/2006.04898">Reposing Humans by Warping 3D Features</a>
        </div>
        <div class="paper-authors">Markus Knoche, <u>István Sárándi</u>, Bastian Leibe</div>
        <div class="paper-venue">IEEE/CVF Conference on Computer Vision and
            Pattern Recognition Workshops (CVPRW), 2020.
        </div>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/2006.04898">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="https://github.com/MKnoche/warp3d_reposing">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code
            </a><a href="https://www.youtube.com/watch?v=U4hfTcF2cHI">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                Talk
            </a><a href="https://doi.org/10.1109/CVPRW50498.2020.00530">
                <span class="icon"><i class="fa fa-external-link-alt"></i></span>
                doi
            </a><a href="javascript:toggleBibtex('bibtex_cvprw20')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_cvprw20">@inproceedings{Knoche2020reposing,
    title = {Reposing Humans by Warping {3D} Features},
    author = {Knoche, Markus and S\'ar\'andi, Istv\'an and Leibe, Bastian},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
    year = {2020}
}</pre>
    </div>
</div>

<div class="paper" id="sarandi20fg">
    <a href="https://arxiv.org/abs/2003.02953"><img src="paper_thumbnails/sarandi20fg.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/2003.02953">Metric-Scale Truncation-Robust Heatmaps for
            3D Human Pose Estimation</a></div>
        <div class="paper-authors"><u>István Sárándi</u>, Timm Linder, Kai O. Arras, Bastian Leibe</div>
        <div class="paper-venue">IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2020.
            <strong>Oral</strong>
        </div>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/2003.02953">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="https://github.com/isarandi/metro-pose3d">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code
            </a><a href="https://doi.org/10.1109/FG47880.2020.00108">
                <span class="icon"><i class="fa fa-external-link-alt"></i></span>
                doi
            </a><a href="javascript:toggleBibtex('bibtex_fg20')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_fg20">@inproceedings{Sarandi2020metro,
    title = {Metric-Scale Truncation-Robust Heatmaps for 3{D} Human Pose Estimation},
    author = {S\'ar\'andi, Istv\'an and Linder, Timm and Arras, Kai O. and Leibe, Bastian},
    booktitle = {IEEE International Conference on Automatic Face and Gesture Recognition (FG)},
    year = {2020}
}</pre>
    </div>
</div>

<div class="paper" id="pfeiffer19gcpr">
    <a href="https://arxiv.org/abs/1906.03019"><img src="paper_thumbnails/pfeiffer19gcpr.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/1906.03019">Visual Person Understanding through
            Multi-Task and Multi-Dataset Learning</a></div>
        <div class="paper-authors">Kilian Pfeiffer, Alexander Hermans, <u>István Sárándi</u>, Mark Weber, Bastian Leibe
        </div>
        <div class="paper-venue">German Conference on Pattern Recognition (GCPR), 2019. (Dortmund, Germany)</div>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/1906.03019">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="media/poster-gcpr19pfeiffer.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Poster
            </a><a href="https://doi.org/10.1007/978-3-030-33676-9_39">
                <span class="icon"><i class="fa fa-external-link-alt"></i></span>
                doi
            </a><a href="javascript:toggleBibtex('bibtex_gcpr19')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_gcpr19">@inproceedings{Pfeiffer2019multitask,
    title = {Visual Person Understanding Through Multi-task and Multi-dataset Learning},
    author = {Pfeiffer, Kilian and Hermans, Alexander and S\'ar\'andi, Istv\'{a}n and Weber, Mark and Leibe, Bastian},
    booktitle = {German Conference on Pattern Recognition (GCPR)},
    date = {2019}
}</pre>
    </div>
</div>

<div class="paper" id="sarandi18eccvw">
    <a href="https://arxiv.org/abs/1809.04987"><img src="paper_thumbnails/sarandi18eccvw.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/1809.04987">
            Synthetic Occlusion Augmentation with Volumetric Heatmaps for the 2018 ECCV PoseTrack Challenge on 3D Human
            Pose Estimation
        </a></div>
        <div class="paper-authors"><u>István Sárándi</u>, Timm Linder, Kai O. Arras, Bastian Leibe</div>
        <div class="paper-venue">Extended abstract, European Conference on Computer Vision Workshops,
            2018. (Munich, Germany)
        </div>
        <span class="icon"><i class="fas fa-trophy"></i></span>
        <a href="https://virtualhumans.mpi-inf.mpg.de/3DPW_Challenge">
            <span>1st place in the ECCV 2018 PoseTrack Challenge on 3D Pose!</span></a>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/1809.04987">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="https://github.com/isarandi/synthetic-occlusion">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code
            </a><a href="media/sarandi18eccvw_slides.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Slides
            </a><a href="media/posetrack3d-sarandi-poster.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Poster
            </a><a href="https://omnomnom.vision.rwth-aachen.de/data/posetrack3d_sarandi.mp4">
                <span class="icon"><i class="fa fa-film"></i></span>
                Video
            </a><a href="javascript:toggleBibtex('bibtex_eccvw18')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_eccvw18">@article{Sarandi2018synthetic,
    title = {Synthetic Occlusion Augmentation with Volumetric Heatmaps for the 2018 {ECCV PoseTrack Challenge} on {3D} Human Pose Estimation},
    author = {S\'ar\'andi, Istv\'an and Linder, Timm and Arras, Kai O. and Leibe, Bastian},
    journal={arXiv preprint arXiv:1809.04987},
    year = {2018}
}</pre>
    </div>
</div>

<div class="paper" id="sarandi18irosw">
    <a href="https://arxiv.org/abs/1808.09316"><img src="paper_thumbnails/sarandi18irosw.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="https://arxiv.org/abs/1808.09316">How Robust is 3D Human Pose Estimation to
            Occlusion?</a></div>
        <div class="paper-authors"><u>István Sárándi</u>, Timm Linder, Kai O. Arras, Bastian Leibe</div>
        <div class="paper-venue">IEEE/RSJ International Conference on Intelligent Robots and Systems, Workshop on
            Robotic Co-Workers 4.0 (IROSW), 2018. (Madrid, Spain)
        </div>
        <div class="paper-links">
            <a href="https://arxiv.org/abs/1808.09316">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                arXiv
            </a><a href="media/poster-irosw18-sarandi.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Poster
            </a><a href="javascript:toggleBibtex('bibtex_irosw18')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_irosw18">@inproceedings{Sarandi2018occlusion,
  title = {How Robust is {3D} Human Pose Estimation to Occlusion?},
  author = {S\'ar\'andi, Istv\'an and Linder, Timm and Arras, Kai O. and Leibe, Bastian},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems Workshops (IROSW)},
  year = {2018}
}</pre>
    </div>
</div>

<h3><a href="medical_informatics.html">Medical Informatics Publications (2013–14)</a></h3>

<h2 id="theses">Theses</h2>

<div class="paper" id="phd-thesis">
    <a href="media/sarandi_phd_thesis.pdf"><img src="paper_thumbnails/metrabs.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/sarandi_phd_thesis.pdf">Robust and Efficient Methods in Visual 3D Human Pose Estimation</a></div>
        <div class="paper-authors"><u>István Sárándi</u></div>
        <div class="paper-venue">PhD thesis, RWTH Aachen University, Germany, 2023.</div>
        <div class="paper-links">
            <a href="media/sarandi_phd_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis
            </a><a href="javascript:toggleBibtex('bibtex_phdthesis')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_phdthesis">@phdthesis{Sarandi2023phdthesis,
    title = {Robust and Efficient Methods in Visual {3D} Human Pose Estimation},
    author = {S\'ar\'andi, Istv\'an},
    school = {RWTH Aachen University},
    year = {2023}
}</pre>
    </div>
</div>

<div class="paper" id="master-thesis">
    <a href="media/sarandi_master_thesis.pdf"><img src="paper_thumbnails/sarandi_master_thesis.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/sarandi_master_thesis.pdf">Pedestrian Line Counting by Probabilistic
            Combination of Flow and Appearance Information</a></div>
        <div class="paper-authors"><u>István Sárándi</u></div>
        <div class="paper-venue">Master’s thesis, RWTH Aachen University, Germany, 2015.</div>
        <div class="paper-links">
            <a href="media/sarandi_master_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis
            </a><a href="https://github.com/isarandi/pedestrian_counting_thesis">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code (C++)
            </a><a href="javascript:toggleBibtex('bibtex_masterthesis')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_masterthesis">@mastersthesis{Sarandi2015mastersthesis,
    title = {Pedestrian Line Counting by Probabilistic Combination of Flow and Appearance Information},
    author = {S\'ar\'andi, Istv\'an},
    school = {RWTH Aachen University},
    year = {2015}
}</pre>
    </div>
</div>

<div class="paper" id="bachelor-thesis">
    <a href="media/sarandi_bachelor_thesis.pdf"><img src="paper_thumbnails/sarandi_bachelor_thesis.png"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/sarandi_bachelor_thesis.pdf">System Development to Support Medical Coding</a>
        </div>
        <div class="paper-subtitle">(HU: Egészségügyi Kódolástámogató Rendszer Fejlesztése)</div>
        <div class="paper-authors"><u>István Sárándi</u></div>
        <div class="paper-venue">Bachelor’s thesis, Budapest University of Technology and Economics, Hungary, 2011.</div>
        <div class="paper-links">
            <a href="media/sarandi_bachelor_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis (in Hungarian)
            </a><a href="media/sarandi_bachelor_thesis_slides.pdf">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Slides (in Hungarian)
            </a><a href="https://github.com/isarandi/medical_coding_thesis">
                <span class="icon"><i class="fab fa-github"></i></span>
                Code (Java)
            </a><a href="javascript:toggleBibtex('bibtex_bachelorthesis')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_bachelorthesis">@mastersthesis{Sarandi2011bachelorsthesis,
    title = {Eg\'eszs\'eg\"ugyi K\'odol\'ast\'amogat\'o Rendszer Fejleszt\'ese},
    author = {S\'ar\'andi, Istv\'an},
    type = {Bachelor’s thesis},
    school = {Budapest University of Technology and Economics},
    year = {2011}
}</pre>
    </div>
</div>

<h3><a href="term_papers.html">Term Papers</a></h3>

<h2 id="students">Supervised Theses</h2>

<div class="paper" id="erlbeck-master-thesis">
    <a href="media/erlbeck_master_thesis.pdf"><img src="paper_thumbnails/erlbeck_master_thesis.png"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/erlbeck_master_thesis.pdf">Temporal Modeling of 3D Human Poses in Multi-Person Interaction Scenarios</a></div>
        <div class="paper-authors">Stefan Erlbeck</div>
        <div class="paper-venue">Master’s thesis, RWTH Aachen University, Germany, 2022.</div>
        <div class="paper-links">
            <a href="media/erlbeck_master_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis
            </a><a href="javascript:toggleBibtex('bibtex_erlbeck22masterthesis')">
            <span class="icon"><i class="fas fa-paperclip"></i></span>
            BibTeX
        </a>
        </div>
        <pre class="bibtex" id="bibtex_erlbeck22masterthesis">@mastersthesis{Erlbeck2022mastersthesis,
    title = {Temporal Modeling of 3D Human Poses in Multi-Person Interaction Scenarios},
    author = {Erlbeck, Stefan},
    school = {RWTH Aachen University},
    year = {2022}
}</pre>
    </div>
</div>


<div class="paper" id="liu-master-thesis">
    <a href="media/liu_master_thesis.pdf"><img src="paper_thumbnails/liu_master_thesis.png"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/liu_master_thesis.pdf">Monocular 3D Human Pose Estimation using Depth as Privileged Information</a></div>
        <div class="paper-authors">Yinglun Liu</div>
        <div class="paper-venue">Master’s thesis, RWTH Aachen University, Germany, 2021.</div>
        <div class="paper-links">
            <a href="media/liu_master_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis
            </a><a href="javascript:toggleBibtex('bibtex_liu21masterthesis')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_liu21masterthesis">@mastersthesis{Liu2021mastersthesis,
    title = {Monocular 3D Human Pose Estimation using Depth as Privileged Information},
    author = {Liu, Yinglun},
    school = {RWTH Aachen University},
    year = {2021}
}</pre>
    </div>
</div>

<div class="paper" id="knoche-master-thesis">
    <a href="media/knoche_master_thesis.pdf"><img src="paper_thumbnails/knoche_master_thesis.jpg"></a>
    <div class="paper-details">
        <div class="paper-title"><a href="media/knoche_master_thesis.pdf">Volumetric Feature Transformation for Pose-Conditioned Human Image Synthesis</a></div>
        <div class="paper-authors">Markus Knoche</div>
        <div class="paper-venue">Master’s thesis, RWTH Aachen University, Germany, 2020.</div>
        <div class="paper-links">
            <a href="media/knoche_master_thesis.pdf">
                <span class="icon"><i class="fa fa-book"></i></span>
                Thesis
            </a><a href="#knoche20cvprw">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                Paper
            </a><a href="javascript:toggleBibtex('bibtex_knoche20masterthesis')">
                <span class="icon"><i class="fas fa-paperclip"></i></span>
                BibTeX
            </a>
        </div>
        <pre class="bibtex" id="bibtex_knoche20masterthesis">@mastersthesis{Knoche2020mastersthesis,
    title = {Volumetric Feature Transformation for Pose-Conditioned Human Image Synthesis},
    author = {Knoche, Markus},
    school = {RWTH Aachen University},
    year = {2020}
}</pre>
    </div>
</div>

<h2 id="teaching">Teaching Assistance</h2>
<ul>
    <li>Winter 2021/22
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/50/">Seminar Current Topics in Computer Vision and
                Machine Learning</a></li>
        </ul>
    </li>
    <li>Summer 2021
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/40/">Deep Learning Laboratory</a></li>
        </ul>
    </li>
    <li>Winter 2020/21
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/38/">Seminar CV+ML</a></li>
        </ul>
    </li>
    <li>Summer 2020
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/33/">Computer Vision</a></li>
            <li><a href="https://www.vision.rwth-aachen.de/course/35/">Seminar CV+ML</a></li>
        </ul>
    </li>
    <li>Winter 2019/20
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/32/">Seminar CV+ML</a></li>
        </ul>
    </li>
    <li>Summer 2019
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/28/">Computer Vision</a></li>
            <li><a href="https://www.vision.rwth-aachen.de/course/27/">Seminar CV+ML</a></li>
        </ul>
    </li>
    <li>Summer 2018
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/21/">Seminar CV+ML</a></li>
        </ul>
    </li>
    <li>Winter 2017/18
        <ul>
            <li><a href="https://www.vision.rwth-aachen.de/course/20">Einführung in die Informatik (Intro to CompSci, in
                German)</a></li>
        </ul>
    </li>
</ul>

<script>
    function toggleBibtex(id) {
        let node = document.getElementById(id)
        node.style.display = node.style.display === "none" ? "block" : "none"
    }
    const bibtex_elements = document.getElementsByClassName('bibtex');
    for (let i = 0; i < bibtex_elements.length; i++) {
        toggleBibtex(bibtex_elements[i].id);
    }
</script>
</body>
</html>

